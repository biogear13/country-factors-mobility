{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6060d44e",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeecf03a",
   "metadata": {},
   "source": [
    "## Improting required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c40f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries for data manipulation\n",
    "import numpy as np            # For numerical operations\n",
    "import pandas as pd           # For structured data (DataFrame) manipulation\n",
    "\n",
    "# Regular expressions for pattern matching\n",
    "import re\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt   # For basic plotting\n",
    "import seaborn as sns             # For statistical plots and visual styles\n",
    "\n",
    "# Dask for out-of-core and parallel data processing (large datasets)\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Glob for file path matching (e.g., loading multiple CSV files at once)\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce91f5d",
   "metadata": {},
   "source": [
    "## Code to check and review each CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b03abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_df(dataframe):\n",
    "    \"\"\"\n",
    "    Evaluate the structure and quality of a pandas DataFrame.\n",
    "    \n",
    "    This function prints:\n",
    "    - Data types and memory usage\n",
    "    - Columns with missing values\n",
    "    - Count of duplicate rows\n",
    "    - Summary statistics (numeric and categorical)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataframe : pd.DataFrame\n",
    "        The DataFrame to evaluate.\n",
    "    \"\"\"\n",
    "    # Display data types and basic memory usage\n",
    "    print(\"\\nüîç DATA TYPES & MEMORY USAGE\")\n",
    "    print(\"-\" * 40)\n",
    "    print(dataframe.info())\n",
    "\n",
    "    # Check and display missing values per column\n",
    "    print(\"\\nüß© MISSING VALUES PER COLUMN\")\n",
    "    print(\"-\" * 40)\n",
    "    missing_values = dataframe.isnull().sum()\n",
    "    print(missing_values[missing_values > 0])\n",
    "\n",
    "    # Check for duplicate rows\n",
    "    duplicates = dataframe.duplicated().sum()\n",
    "    print(\"\\nüóÉÔ∏è DUPLICATE ROWS FOUND\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"{duplicates} duplicate rows found.\")\n",
    "\n",
    "    # Display summary statistics (for both numeric and object types)\n",
    "    print(\"\\nüìä SUMMARY STATISTICS\")\n",
    "    print(\"-\" * 40)\n",
    "    print(dataframe.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b4d0da",
   "metadata": {},
   "source": [
    "## Get the sample countries  \n",
    "- this would include those that have mobility data, policy data, covid data and country statistics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee7cb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>alpha2</th>\n",
       "      <th>alpha3</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>af</td>\n",
       "      <td>afg</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>al</td>\n",
       "      <td>alb</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>dz</td>\n",
       "      <td>dza</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>ad</td>\n",
       "      <td>and</td>\n",
       "      <td>Andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>ao</td>\n",
       "      <td>ago</td>\n",
       "      <td>Angola</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id alpha2 alpha3           en\n",
       "0   4     af    afg  Afghanistan\n",
       "1   8     al    alb      Albania\n",
       "2  12     dz    dza      Algeria\n",
       "3  20     ad    and      Andorra\n",
       "4  24     ao    ago       Angola"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get a common code for the countries I would use the ISO 3166-1 alpha-3\n",
    "# Load country and country code reference data\n",
    "COUNTRY_CODE = pd.read_csv(\"data/country_codes.csv\")\n",
    "\n",
    "# Preview the first few rows\n",
    "COUNTRY_CODE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3913b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capitalise all codes in alpha2 and alpha3\n",
    "COUNTRY_CODE['alpha2'] = COUNTRY_CODE['alpha2'].str.upper()\n",
    "COUNTRY_CODE['alpha3'] = COUNTRY_CODE['alpha3'].str.upper() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba05cec7",
   "metadata": {},
   "source": [
    "### Get the mobility data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9819c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to exclude from loading\n",
    "excluded_cols = ['iso_3166_2_code', 'census_flips_code', 'place_id']\n",
    "\n",
    "# Sample the file to get full column list, then exclude unwanted ones\n",
    "all_cols = dd.read_csv('data/global_mobility_report.csv', sample=10000).columns.tolist()\n",
    "usecols = [col for col in all_cols if col not in excluded_cols]\n",
    "\n",
    "# Load the dataset using only the desired columns\n",
    "# assume_missing=True is important for mixed types in large files\n",
    "mobility_data = dd.read_csv('data/global_mobility_report.csv', usecols=usecols, assume_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8008449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country_region_code        country_region sub_region_1 sub_region_2  \\\n",
      "0                  AE  United Arab Emirates         <NA>         <NA>   \n",
      "1                  AE  United Arab Emirates         <NA>         <NA>   \n",
      "2                  AE  United Arab Emirates         <NA>         <NA>   \n",
      "3                  AE  United Arab Emirates         <NA>         <NA>   \n",
      "4                  AE  United Arab Emirates         <NA>         <NA>   \n",
      "5                  AE  United Arab Emirates         <NA>         <NA>   \n",
      "6                  AE  United Arab Emirates         <NA>         <NA>   \n",
      "7                  AE  United Arab Emirates         <NA>         <NA>   \n",
      "8                  AE  United Arab Emirates         <NA>         <NA>   \n",
      "9                  AE  United Arab Emirates         <NA>         <NA>   \n",
      "\n",
      "  metro_area       date  retail_and_recreation_percent_change_from_baseline  \\\n",
      "0       <NA> 2020-02-15                                                0.0    \n",
      "1       <NA> 2020-02-16                                                1.0    \n",
      "2       <NA> 2020-02-17                                               -1.0    \n",
      "3       <NA> 2020-02-18                                               -2.0    \n",
      "4       <NA> 2020-02-19                                               -2.0    \n",
      "5       <NA> 2020-02-20                                               -2.0    \n",
      "6       <NA> 2020-02-21                                               -3.0    \n",
      "7       <NA> 2020-02-22                                               -2.0    \n",
      "8       <NA> 2020-02-23                                               -1.0    \n",
      "9       <NA> 2020-02-24                                               -3.0    \n",
      "\n",
      "   grocery_and_pharmacy_percent_change_from_baseline  \\\n",
      "0                                                4.0   \n",
      "1                                                4.0   \n",
      "2                                                1.0   \n",
      "3                                                1.0   \n",
      "4                                                0.0   \n",
      "5                                                1.0   \n",
      "6                                                2.0   \n",
      "7                                                2.0   \n",
      "8                                                3.0   \n",
      "9                                                0.0   \n",
      "\n",
      "   parks_percent_change_from_baseline  \\\n",
      "0                                 5.0   \n",
      "1                                 4.0   \n",
      "2                                 5.0   \n",
      "3                                 5.0   \n",
      "4                                 4.0   \n",
      "5                                 6.0   \n",
      "6                                 6.0   \n",
      "7                                 4.0   \n",
      "8                                 3.0   \n",
      "9                                 5.0   \n",
      "\n",
      "   transit_stations_percent_change_from_baseline  \\\n",
      "0                                            0.0   \n",
      "1                                            1.0   \n",
      "2                                            1.0   \n",
      "3                                            0.0   \n",
      "4                                           -1.0   \n",
      "5                                            1.0   \n",
      "6                                            0.0   \n",
      "7                                           -2.0   \n",
      "8                                           -1.0   \n",
      "9                                           -1.0   \n",
      "\n",
      "   workplaces_percent_change_from_baseline  \\\n",
      "0                                      2.0   \n",
      "1                                      2.0   \n",
      "2                                      2.0   \n",
      "3                                      2.0   \n",
      "4                                      2.0   \n",
      "5                                      1.0   \n",
      "6                                     -1.0   \n",
      "7                                      3.0   \n",
      "8                                      4.0   \n",
      "9                                      3.0   \n",
      "\n",
      "   residential_percent_change_from_baseline  \n",
      "0                                       1.0  \n",
      "1                                       1.0  \n",
      "2                                       1.0  \n",
      "3                                       1.0  \n",
      "4                                       1.0  \n",
      "5                                       1.0  \n",
      "6                                       1.0  \n",
      "7                                       1.0  \n",
      "8                                       1.0  \n",
      "9                                       1.0  \n"
     ]
    }
   ],
   "source": [
    "# Columns to include (mobility trends + region info + date)\n",
    "usecols = [\n",
    "    \"country_region_code\", \"country_region\", \"sub_region_1\", \"sub_region_2\", \"metro_area\",\n",
    "    \"date\", \"retail_and_recreation_percent_change_from_baseline\",\n",
    "    \"grocery_and_pharmacy_percent_change_from_baseline\",\n",
    "    \"parks_percent_change_from_baseline\",\n",
    "    \"transit_stations_percent_change_from_baseline\",\n",
    "    \"workplaces_percent_change_from_baseline\",\n",
    "    \"residential_percent_change_from_baseline\"\n",
    "]\n",
    "\n",
    "# Explicit dtypes to avoid Dask inference issues\n",
    "dtype_fix = {\n",
    "    'sub_region_1': 'object',\n",
    "    'sub_region_2': 'object',\n",
    "    'metro_area': 'object'\n",
    "}\n",
    "\n",
    "# Load the dataset with parsing and type fixes\n",
    "df = dd.read_csv(\n",
    "    'data/global_mobility_report.csv',\n",
    "    usecols=usecols,\n",
    "    dtype=dtype_fix,\n",
    "    parse_dates=['date'],\n",
    "    assume_missing=True\n",
    ")\n",
    "\n",
    "# Filter: only country-level data + dates up to Jan 31, 2021\n",
    "missing_cols = ['sub_region_1', 'sub_region_2', 'metro_area']\n",
    "filtered = df[\n",
    "    df[missing_cols].isnull().all(axis=1) &\n",
    "    (df['date'] <= '2022-12-31')\n",
    "]\n",
    "\n",
    "# Safely preview the filtered result\n",
    "print(filtered.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
